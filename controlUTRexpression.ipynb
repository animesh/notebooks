{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:42:51.390669Z",
     "start_time": "2019-03-03T21:42:48.948824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: numpy in /home/ash022/.local/lib/python3.6/site-packages (from torchvision) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision) (5.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision #--upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:45:41.710587Z",
     "start_time": "2019-03-03T21:44:27.137643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "  Using cached https://files.pythonhosted.org/packages/98/6c/6b6d34dc783f1535190bfafbc5c0063656f06a3dd5c37b2b2b7bd0e8011e/fastai-1.0.46-py3-none-any.whl\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from fastai) (18.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from fastai) (3.0.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.6/site-packages (from fastai) (2.6.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from fastai) (3.13)\n",
      "Collecting torch>=1.0.0 (from fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/31/ca/dd2c64f8ab5e7985c4af6e62da933849293906edcdb70dac679c93477733/torch-1.0.1.post2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from fastai) (0.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from fastai) (0.23.4)\n",
      "Collecting nvidia-ml-py3 (from fastai)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from fastai) (0.6)\n",
      "Collecting fastprogress>=0.1.19 (from fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/86/30/01f597392e4e7b4982f387028da941e1fd60a8d53511d17225858d87fb22/fastprogress-0.1.20-py3-none-any.whl\n",
      "Collecting spacy>=2.0.18 (from fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/6e/a89da6b5c83f8811e46e3a9270c1aed90e9b9ee6c60faf52b7239e5d3d69/spacy-2.0.18-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from fastai) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ash022/.local/lib/python3.6/site-packages (from fastai) (1.15.0)\n",
      "Collecting bottleneck (from fastai)\n",
      "Requirement already satisfied: typing in /opt/conda/lib/python3.6/site-packages (from fastai) (3.6.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from fastai) (2.20.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.6/site-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from fastai) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from packaging->fastai) (1.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->fastai) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->fastai) (2.7.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->fastai) (1.0.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->fastai) (2018.7)\n",
      "Collecting preshed<2.1.0,>=2.0.1 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (0.28.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/61/9b0520c28eb199a4b1ca667d96dd625bba003c14c75230195f9691975f85/cymem-2.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting regex==2018.01.10 (from spacy>=2.0.18->fastai)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /opt/conda/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (0.2.8.2)\n",
      "Collecting thinc<6.13.0,>=6.12.1 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/db/a7/46640a46fd707aeb204aa4257a70974b6a22a0204ba703164d803215776f/thinc-6.12.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: ujson>=1.35 in /opt/conda/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (1.35)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->fastai) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->fastai) (2018.10.15)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->fastai) (2.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (40.6.2)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
      "Collecting msgpack-numpy<0.4.4 (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/45/464be6da85b5ca893cfcbd5de3b31a6710f636ccb8521b17bd4110a08d94/msgpack_numpy-0.4.3.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.28.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n",
      "Installing collected packages: torch, nvidia-ml-py3, fastprogress, cymem, preshed, regex, msgpack-numpy, thinc, spacy, bottleneck, fastai\n",
      "\u001b[33m  The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/ash022/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed bottleneck-1.2.1 cymem-2.0.2 fastai-1.0.46 fastprogress-0.1.20 msgpack-numpy-0.4.3.2 nvidia-ml-py3-7.352.0 preshed-2.0.1 regex-2018.1.10 spacy-2.0.18 thinc-6.12.1 torch-1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:47:07.703426Z",
     "start_time": "2019-03-03T21:47:06.297023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:55:54.864778Z",
     "start_time": "2019-03-03T21:55:54.859297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.45], [0.5, 0.55]] [[0.15, 0.2], [0.25, 0.3]]\n"
     ]
    }
   ],
   "source": [
    "#coding https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ with pytorch, checking with iterative version at  https://github.com/animesh/ann/blob/master/ann/Program.cs with following output\n",
    "#Iteration = 1   Error = 0.298371108760003       Outputs = 0.751365069552316     0.772928465321463\n",
    "#Iteration = 2   Error = 0.291027773693599       Outputs = 0.742088111190782     0.775284968294459  ...\n",
    "\n",
    "inp=[0.05,0.10]\n",
    "inpw=[[0.15,0.20],[0.25,0.3]]\n",
    "hidw=[[0.4,0.45],[0.5,0.55]]\n",
    "outputr=[0.01,0.99]\n",
    "bias=[0.35,0.6]\n",
    "lr=0.5\n",
    "print(hidw,inpw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:55:57.609950Z",
     "start_time": "2019-03-03T21:55:57.603664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04882595 -1.75240764]\n",
      " [ 1.03842014 -1.32174912]] [[-0.98008459 -0.78336538]\n",
      " [ 0.45783472 -0.90748975]]\n"
     ]
    }
   ],
   "source": [
    "#\"ALL YOU NEED IS A GOOD INIT\" https://arxiv.org/pdf/1511.06422.pdf\n",
    "import numpy as np\n",
    "inpw=np.random.randn(len(outputr),int(len(inp)*np.sqrt(2/len(inp))))\n",
    "hidw=np.random.randn(len(outputr),int(len(inp)*np.sqrt(2/len(inp))))\n",
    "print(inpw,hidw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:56:36.552219Z",
     "start_time": "2019-03-03T21:56:30.309821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.Size([2]) tensor([0.0100, 0.9900], device='cuda:0', dtype=torch.float64) tensor([0.3500, 0.6000], device='cuda:0', dtype=torch.float64) torch.Size([2, 2]) tensor([[-0.9801, -0.7834],\n",
      "        [ 0.4578, -0.9075]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(Device)\n",
    "x=torch.tensor(inp, dtype=torch.double, device=Device)\n",
    "y=torch.tensor(outputr, dtype=torch.double, device=Device)\n",
    "b=torch.tensor(bias, dtype=torch.double, device=Device)\n",
    "w1=torch.tensor(inpw, dtype=torch.double, device=Device)\n",
    "w2=torch.tensor(hidw, dtype=torch.double, device=Device)\n",
    "print(x.size(),y,b,w1.size(),w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T21:56:43.554772Z",
     "start_time": "2019-03-03T21:56:43.403376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 MSE:  tensor(0.1616, device='cuda:0', dtype=torch.float64)\n",
      "tensor([[ 0.0488, -1.7524],\n",
      "        [ 1.0384, -1.3217]], device='cuda:0', dtype=torch.float64)\n",
      "tensor([[-0.9801, -0.7834],\n",
      "        [ 0.4578, -0.9075]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "while iter<1:\n",
    "    iter+=1\n",
    "    h = torch.sigmoid(x.matmul(w1.transpose(0,1))+b[0])\n",
    "    y_pred = torch.sigmoid(h.matmul(w2.transpose(0,1))+b[1])\n",
    "    print(\"iteration:\",iter,\"MSE: \",0.5*(((y_pred - y).pow(2)).sum()))\n",
    "    print(w1)\n",
    "    print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T10:53:23.577725Z",
     "start_time": "2019-02-21T10:53:23.555159Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0\n",
    "class Neural_Network(torch.nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        self.W1 = w1.transpose(0,1) # 3 x 2 tensor\n",
    "        self.W2 = w2.transpose(0,1)\n",
    "    def forward(self, x):\n",
    "        self.z = torch.matmul(x, self.W1) # 3 x 3 \".dot\" does not broadcast in PyTorch\n",
    "        self.z2 = self.sigmoid(self.z) # activation function\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) # final activation function\n",
    "        return o\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    def backward(self, x, y, o):\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        self.W1 += torch.matmul(x, self.z2_delta.transpose(0,1)) #torch.sigmoid(x.matmul(w1.transpose(0,1))+b[0])\n",
    "        self.W2 += torch.matmul(self.z2, self.o_delta)\n",
    "    def train(self, x, y):\n",
    "        o = self.forward(x)\n",
    "        self.backward(x, y, o)\n",
    "    def saveWeights(self, model):\n",
    "        torch.save(model, \"NN\")\n",
    "    def predict(self):\n",
    "        print (\"Predicted weights: \")\n",
    "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
    "        print (\"Output: \\n\" + str(self.forward(xPredicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T10:53:28.753811Z",
     "start_time": "2019-02-21T10:53:28.682749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.24251985734837728\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-55261c524c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# trains the NN 1,000 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean sum squared loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5644b2f6dc70>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msaveWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5644b2f6dc70>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, o)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#torch.sigmoid(x.matmul(w1.transpose(0,1))+b[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(1000):  # trains the NN 1,000 times\n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(x))**2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(x, y)\n",
    "NN.saveWeights(NN)\n",
    "NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:03:05.969359Z",
     "start_time": "2019-02-22T10:03:03.035789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "sns.set(style='white', rc={'figure.figsize':(14, 12)})\n",
    "from sklearn.datasets import load_digits\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:07:52.815018Z",
     "start_time": "2019-02-22T10:07:48.202306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: UMAP in /opt/conda/lib/python3.6/site-packages (0.1.1)\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install hypertools\n",
    "!pip3 install UMAP\n",
    "#!pip3 install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:03:34.309372Z",
     "start_time": "2019-02-22T10:03:34.171984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "data = digits.data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:03:46.026298Z",
     "start_time": "2019-02-22T10:03:46.017918Z"
    }
   },
   "outputs": [],
   "source": [
    "def tween(e1, e2, n_frames=20):\n",
    "    for i in range(5):\n",
    "        yield e1\n",
    "    for i in range(n_frames):\n",
    "        alpha = i / float(n_frames - 1)\n",
    "        yield (1 - alpha) * e1 + alpha * e2\n",
    "    for i in range(5):\n",
    "        yield(e2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:04:01.852639Z",
     "start_time": "2019-02-22T10:04:01.839854Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_frame_data(data, arg_name='n_neighbors', arg_list=[3,4,5,7,9,11,15,20,25,30,40,60,100]):\n",
    "    result = []\n",
    "    es = []\n",
    "    for arg in arg_list:\n",
    "        kwargs = {arg_name:arg}\n",
    "        if len(es) > 0:\n",
    "            es.append(UMAP(init=es[-1], negative_sample_rate=3, **kwargs).fit_transform(data))\n",
    "        else:\n",
    "            es.append(UMAP(negative_sample_rate=3, **kwargs).fit_transform(data))\n",
    "        \n",
    "    for e1, e2 in zip(es[:-1], es[1:]):\n",
    "        result.extend(list(tween(e1, e2)))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:04:15.987838Z",
     "start_time": "2019-02-22T10:04:15.963035Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_animation(frame_data, arg_name='n_neighbors', arg_list=[3,4,5,7,9,11,15,20,25,30,40,60,100]):\n",
    "    fig = plt.figure()\n",
    "    all_data = np.vstack(frame_data)\n",
    "    frame_bounds = (all_data[:, 0].min() * 1.1, \n",
    "                    all_data[:, 0].max() * 1.1,\n",
    "                    all_data[:, 1].min() * 1.1, \n",
    "                    all_data[:, 1].max() * 1.1)\n",
    "    ax = plt.axes(xlim=(frame_bounds[0], frame_bounds[1]), \n",
    "                  ylim=(frame_bounds[2], frame_bounds[3]))\n",
    "    points = plt.scatter(frame_data[0][:, 0], frame_data[0][:, 1], \n",
    "                        s=5, c=digits.target, cmap='Spectral', animated=True)\n",
    "    title = plt.title('', fontsize=24)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    cbar = plt.colorbar(values=np.arange(10), boundaries=np.arange(11)-0.5, ticks=np.arange(10), drawedges=True)\n",
    "    cbar.ax.yaxis.set_ticklabels(np.arange(10), fontsize=18)\n",
    "\n",
    "    def init():\n",
    "        points.set_offsets(frame_data[0])\n",
    "        title.set_text('UMAP with {}={}'.format(arg_name, arg_list[0]))\n",
    "        return points,\n",
    "\n",
    "    def animate(i):\n",
    "        points.set_offsets(frame_data[i])\n",
    "        if (i + 15) % 30 == 0:\n",
    "            title.set_text('UMAP with {}={}'.format(arg_name, arg_list[(i + 15) // 30]))\n",
    "        return points,\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(frame_data), interval=20, blit=True)\n",
    "    anim.save('umap_anim-{}.gif'.format(arg_name), writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:04:27.929611Z",
     "start_time": "2019-02-22T10:04:27.922796Z"
    }
   },
   "outputs": [],
   "source": [
    "def animate_param(data, arg_name='n_neighbors', arg_list=[3,4,5,7,9,11,15,20,25,30,40,60,100]):\n",
    "    frame_data = generate_frame_data(data, arg_name, arg_list)\n",
    "    create_animation(frame_data, arg_name, arg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T10:15:59.213120Z",
     "start_time": "2019-02-22T10:15:57.356061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imagemagick\n",
      "\u001b[31m  Could not find a version that satisfies the requirement imagemagick (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for imagemagick\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#import ffmpeg \n",
    "!pip3 install imagemagick\n",
    "#animate_param(data, 'n_neighbors', [3,4,5,7,10,15])\n",
    "#animate_param(data, 'min_dist', [0.0, 0.01, 0.1, 0.2, 0.4, 0.6, 0.9])\n",
    "#animate_param(data, 'gamma', [0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0])\n",
    "#animate_param(data, 'local_connectivity', [0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0])\n",
    "#animate_param(data, 'bandwidth', [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0])\n",
    "#animate_param(data, 'set_op_mix_ratio', np.linspace(0.0, 1.0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"posw.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data['RFPlog']=np.log2(data['RFP'])\n",
    "data.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "DNAortho = ('A','1000') , ('T','0100') ,  ('G','0010'), ('C','0001')\n",
    "data['DNASeqOrtho']=reduce(lambda a, kv: a.str.replace(*kv), DNAortho, data['DNASeq'])\n",
    "data['DNASeqOrtho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Variable(torch.Tensor(data['DNASeqOrtho'].apply(lambda x: float(x.find('10'))).reshape(-1,1))).cuda()\n",
    "y=Variable(torch.Tensor(data['RFPlog'].reshape(-1,1))).cuda()\n",
    "X, y\n",
    "#int(data['DNASeqOrtho'].sum(),2)\n",
    "#data['DNASeqOrtho'].apply(lambda x: x.find('1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__() \n",
    "        self.linear = nn.Linear(input_dim, output_dim,bias=True).cuda()\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "l_rate = 0.01\n",
    "model = LinearRegressionModel(input_dim,output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr = l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch +=1\n",
    "    optimiser.zero_grad()\n",
    "    outputs = model.forward(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()# back props\n",
    "    optimiser.step()# update the parameters\n",
    "    print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted =model.forward(X).cpu().data.numpy()\n",
    "#plt.plot(X, y, 'i', label = 'from data', alpha = .5)\n",
    "plt.plot(y.cpu().data.numpy(), predicted, label = 'prediction', alpha = 0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html#sphx-glr-beginner-blitz-data-parallel-tutorial-py\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "batch_size = 30\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, 100),\n",
    "                         batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"  In Model: input size\", input.size(),\n",
    "              \"output size\", output.size())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in rand_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        input_var = Variable(data.cuda())\n",
    "    else:\n",
    "        input_var = Variable(data)\n",
    "\n",
    "    output = model(input_var)\n",
    "    print(\"Outside: input size\", input_var.size(),\n",
    "          \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('GPU available to Torch: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('F:/OneDrive - NTNU/UTR/data2.csv')\n",
    "df.head()\n",
    "df.describe()\n",
    "\n",
    "import numpy as np\n",
    "df['RFPlog']=np.log2(data['Fluorescence'])\n",
    "df['RFPlog'].hist()\n",
    "\n",
    "df['ReadsLog']=np.log2(df['#Reads Col'])\n",
    "df['ReadsLog'].hist()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df['RFPlog'],df['ReadsLog'])\n",
    "\n",
    "sorted_inds = df.sort_values('RFPlog').index.values\n",
    "train_inds = sorted_inds[:int(0.1*len(sorted_inds))] # 95% of the data as the training set\n",
    "test_inds = sorted_inds[int(0.1*len(sorted_inds)):] # UTRs with most reads at time point 0 as the test set\n",
    "val_idx = int(0.9*len(train_inds))\n",
    "val_inds = train_inds[val_idx:]\n",
    "train_inds = train_inds[:val_idx]\n",
    "print(len(train_inds))\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from ipywidgets import IntProgress\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, df, seq_len):\n",
    "        self.data = df\n",
    "        self.bases = ['A','C','G','T']\n",
    "        self.base_dict = dict(zip(self.bases,range(4))) # {'A' : 0, 'C' : 1, 'G' : 2, 'T' : 3}\n",
    "        self.total_width = seq_len + 20\n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0])\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data.iloc[idx].UTR\n",
    "        X = np.zeros((1, 4, self.total_width))\n",
    "        y = self.data.iloc[idx].growth_rate\n",
    "        for b in range(len(seq)):\n",
    "            # this will assign a 1 to the appropriate base and position for this UTR sequence\n",
    "            X[0, self.base_dict[seq[b]], int(b + round((self.total_width - len(seq))/2.))] = 1.\n",
    "        return(seq, X, y)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(4, 13))\n",
    "        self.dropout = nn.Dropout(p=0.15)\n",
    "        self.conv2 = nn.Conv2d(128, 128, (1,13))\n",
    "        self.fc1 = nn.Linear(128 * 1 * 34, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 128 * 1 * 34)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "#net = net.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train_data = DNADataset(df.iloc[train_inds], seq_len=50)\n",
    "val_data = DNADataset(df.iloc[val_inds], seq_len=50)\n",
    "test_data = DNADataset(df.iloc[test_inds], seq_len=50)\n",
    "train_data_loader = DataLoader(train_data, batch_size=32,shuffle=True, num_workers=4)\n",
    "\n",
    "val_data_loader = DataLoader(val_data, batch_size=32) # Validate everything in one batch?!\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data)) # Validate everything in one batch?!\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i_batch, sampled_batch in enumerate(tqdm(train_data_loader)):\n",
    "        sequence, transformed_sequence, growth_rate = sampled_batch\n",
    "        #inputs, labels = Variable(transformed_sequence.float().cuda()), Variable(growth_rate.float().cuda())\n",
    "        inputs, labels = Variable(transformed_sequence.float()), Variable(growth_rate.float())\n",
    "        optimizer.zero_grad()\n",
    "        net.train()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    error = 0\n",
    "    totalE = 0\n",
    "    net.eval()\n",
    "    for batch in tqdm(val_data_loader):\n",
    "      v_seq, X_v, y_v = batch\n",
    "      v_pred = net(Variable(X_v.float()))#.cuda()))\n",
    "      totalE = totalE + y_v.size(0)\n",
    "      raw_error = v_pred[:,0].data - y_v.float()#.cuda()\n",
    "      error += (raw_error**2).sum()\n",
    "      avg_mse = error / float(totalE)\n",
    "\n",
    "torch.save(net, 'saved_model.t7')\n",
    "\n",
    "error = 0\n",
    "total = 0\n",
    "for batch in tqdm(val_data_loader):\n",
    "                v_seq, X_v, y_v = batch\n",
    "                v_pred = net(Variable(X_v.float()))#.cuda()))\n",
    "                total += y_v.size(0)\n",
    "                raw_error = v_pred[:,0].data - y_v.float()#.cuda()\n",
    "                error += (raw_error**2).sum()\n",
    "\n",
    "avg_mse = error / float(total)\n",
    "print(\"Validation error: {}\".format(avg_mse))\n",
    "\n",
    "error = 0\n",
    "total = 0\n",
    "for batch in tqdm(test_data_loader):\n",
    "                v_seq, X_v, y_v = batch\n",
    "                v_pred = net(Variable(X_v.float()))#.cuda()))\n",
    "                total += y_v.size(0)\n",
    "                raw_error = v_pred[:,0].data - y_v.float()#.cuda()\n",
    "                error += (raw_error**2).sum()\n",
    "\n",
    "avg_mse = error / float(total)\n",
    "print(\"Test error: {}\".format(avg_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?time_continue=96&v=vMZ7tK-RYYc\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from numba import vectorize, cuda\n",
    "\n",
    "#@vectorize(['float32(float32,float32)'],target='cuda')\n",
    "def subVector(ε,σ):\n",
    "    return ε + σ\n",
    "\n",
    "Elements=10000\n",
    "A=np.ones(Elements,dtype=np.float32)\n",
    "B=np.ones(Elements,dtype=np.float32)\n",
    "C=subVector(A,B)\n",
    "ts=time.time()\n",
    "te=time.time()\n",
    "print(C,te-ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI\n",
    "from pyro.optim import Adam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
