{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7182738780975342\n",
      "1.718078851699829\n",
      "1.7182437181472778\n",
      "1.7193880081176758\n",
      "1.7181984186172485\n",
      "1.7188392877578735\n",
      "1.7175267934799194\n",
      "1.7186293601989746\n",
      "1.7186734676361084\n",
      "1.7179497480392456\n",
      "10.000000 seconds 505\n",
      "val \n",
      " 8.7814e-01\n",
      " 1.9840e-01\n",
      " 2.6958e-01\n",
      "     â‹®     \n",
      " 2.5200e-01\n",
      " 8.3464e-01\n",
      " 7.3883e-01\n",
      "[torch.cuda.FloatTensor of size 1000000 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import time\n",
    "iters = 10\n",
    "vlen = iters * (iters*10) * (iters*100) \n",
    "ts = time.time()\n",
    "for i in range(iters):\n",
    "    rng = torch.rand(vlen).cuda()\n",
    "    print(torch.exp(rng).cuda().mean())\n",
    "te = time.time()\n",
    "print(\"%f seconds %d\" % (iters, te - ts))\n",
    "print(\"val %s\" % rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyro\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI\n",
    "from pyro.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2500\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng=2\n",
    "input1 = torch.rand(64*rng, 3*rng, 128*rng, 128*rng).cuda()\n",
    "input2 = torch.rand(64*rng, 3*rng, 128*rng, 128*rng).cuda()\n",
    "input1 = torch.autograd.Variable(input1, requires_grad=True)\n",
    "input2 = torch.autograd.Variable(input2, requires_grad=True)\n",
    "expected = torch.mul(input1, input2)\n",
    "expected.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-2.0\n",
      "-1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.],\n",
       "       [-1.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y=np.linspace(1,-1,3)\n",
    "x=np.linspace(1,3,3)\n",
    "xy=0\n",
    "for i,j in zip(x,y):\n",
    "    xy+=((i-x.mean())*(j-y.mean()))\n",
    "    print(xy)\n",
    "print(xy/(x.std()*y.std())/3)\n",
    "np.correlate(x,y)\n",
    "np.correlate((x-x.mean())/x.std(),(y-y.mean())/y.std())\n",
    "np.corrcoef((x-x.mean())/x.std(),(y-y.mean())/y.std())\n",
    "#np.corrcoef(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f86d80051d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "N=100\n",
    "x = np.linspace(-6, 6, num=N)\n",
    "#x,y,z=build_linear_dataset(100)\n",
    "y=x*x\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100  # size of toy data\n",
    "p = 1    # number of features\n",
    "\n",
    "def build_linear_dataset(N, noise_std=0.1):\n",
    "    X = np.linspace(-6, 6, num=N)\n",
    "    y = 3 * X + 1 + np.random.normal(0, noise_std, size=N)\n",
    "    X, y = X.reshape((N, 1)), y.reshape((N, 1))\n",
    "    X, y = Variable(torch.Tensor(X)), Variable(torch.Tensor(y))\n",
    "    return torch.cat((X, y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "regression_model = RegressionModel(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 4405.9434\n",
      "[iteration 0100] loss: 2648.9011\n",
      "[iteration 0150] loss: 1519.3024\n",
      "[iteration 0200] loss: 841.0806\n",
      "[iteration 0250] loss: 464.6938\n",
      "[iteration 0300] loss: 272.8968\n",
      "[iteration 0350] loss: 183.5457\n",
      "[iteration 0400] loss: 145.5780\n",
      "[iteration 0450] loss: 130.8732\n",
      "[iteration 0500] loss: 125.6824\n",
      "Learned parameters:\n",
      "linear.weight: 2.988\n",
      "linear.bias: 1.073\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optim = torch.optim.Adam(regression_model.parameters(), lr=0.01)\n",
    "num_iterations = 500\n",
    "\n",
    "def main():\n",
    "    data = build_linear_dataset(N, p)\n",
    "    x_data = data[:, :-1]\n",
    "    y_data = data[:, -1]\n",
    "    for j in range(num_iterations):\n",
    "        # run the model forward on the data\n",
    "        y_pred = regression_model(x_data)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y_data)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        if (j + 1) % 50 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.data[0]))\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in regression_model.named_parameters():\n",
    "        print(\"%s: %.3f\" % (name, param.data.numpy()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html#sphx-glr-beginner-blitz-data-parallel-tutorial-py\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "batch_size = 30\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, 100),\n",
    "                         batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"  In Model: input size\", input.size(),\n",
    "              \"output size\", output.size())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "  In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n",
      "  In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n",
      "Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "for data in rand_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        input_var = Variable(data.cuda())\n",
    "    else:\n",
    "        input_var = Variable(data)\n",
    "\n",
    "    output = model(input_var)\n",
    "    print(\"Outside: input size\", input_var.size(),\n",
    "          \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"posw.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#plt.hist(np.log2(data['expression']))\n",
    "data.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. ... 2. 2. 2.] 4.291534423828125e-05\n"
     ]
    }
   ],
   "source": [
    "#https://www.youtube.com/watch?time_continue=96&v=vMZ7tK-RYYc\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from numba import vectorize, cuda\n",
    "\n",
    "#@vectorize(['float32(float32,float32)'],target='cuda')\n",
    "def subVector(Îµ,Ïƒ):\n",
    "    return Îµ + Ïƒ\n",
    "\n",
    "Elements=10000000000\n",
    "A=np.ones(Elements,dtype=np.float32)\n",
    "B=np.ones(Elements,dtype=np.float32)\n",
    "C=subVector(A,B)\n",
    "ts=time.time()\n",
    "te=time.time()\n",
    "print(C,te-ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
