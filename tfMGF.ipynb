{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Peptide spectra predictor\n",
    "- [Novo](https://github.com/nh2tran/DeepNovo)\n",
    "- [Post](https://github.com/semiller10/postnovo)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/animesh/notebooks/blob/master/tfMGF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "#print(tf.executing_eagerly())\n",
    "print(tf.test.is_gpu_available())#:with tf.device(\"/gpu:0\"):\n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:58:15.850281Z",
     "start_time": "2018-10-03T09:58:14.618490Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "WfAzO1RHxQ4P",
    "outputId": "32f7b902-3926-4e68-f263-fe24a2384ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/promec-ns9036k/NORSTORE_OSL_DISK/NS9036K/promec/promec/Animesh/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "#from  rulsif import RULSIF\n",
    "#from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tf.placeholder(tf.float32)\n",
    "# Make a normal distribution, with a shifting mean\n",
    "mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n",
    "# Record that distribution into a histogram summary\n",
    "tf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n",
    "\n",
    "# Setup a session and summary writer\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(\"/mnt/promec-ns9036k/.tools/brown-swan-tensorboard/histogram\")\n",
    "\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Setup a loop and write the summaries to disk\n",
    "N = 400\n",
    "#for step in range(N):\n",
    "#  k_val = step/float(N)\n",
    "#  summ = sess.run(summaries, feed_dict={k: k_val})\n",
    "#  writer.add_summary(summ, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 16} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "x=base_model.output\n",
    "#x=GlobalAveragePooling4D()(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "preds=Dense(2,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 170s 1s/step - loss: 0.1500 - acc: 0.9344\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 76s 465ms/step - loss: 0.0643 - acc: 0.9795\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 70s 429ms/step - loss: 0.0659 - acc: 0.9781\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 70s 429ms/step - loss: 0.0441 - acc: 0.9875\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 70s 427ms/step - loss: 0.0246 - acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34c5edc940>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator=train_datagen.flow_from_directory('./train',\n",
    "                                                  target_size=(299,299),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical', shuffle=True)\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,steps_per_epoch=step_size_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bzip2: Output file modelMGF.h5.bz2 already exists.\n"
     ]
    }
   ],
   "source": [
    "model.save('modelMGF.h5')    \n",
    "!bzip2 'modelMGF.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseMGF(mgfData):\n",
    "    data = mgfData.read_text().split('\\n')\n",
    "    _comments = '#;!/'\n",
    "    reading_spectrum = False\n",
    "    params = {}\n",
    "    masses = []\n",
    "    intensities = []\n",
    "    charges = []\n",
    "    out = {}\n",
    "    cnt = 0\n",
    "    pep_mass = 0\n",
    "    pep_intensity = 0\n",
    "    out = {}\n",
    "    for line in data:\n",
    "        if not reading_spectrum:\n",
    "            if line.strip() == 'BEGIN IONS': reading_spectrum = True\n",
    "        else:\n",
    "            if not line.strip() or any(line.startswith(c) for c in _comments): pass\n",
    "            elif line.strip() == 'END IONS':\n",
    "                reading_spectrum = False\n",
    "                title = params['title'].split()[0]\n",
    "                if 'pepmass' in params:\n",
    "                    try:\n",
    "                        pl = params['pepmass'].split()\n",
    "                        if len(pl) > 1:\n",
    "                            pep_mass = float(pl[0])\n",
    "                            pep_intensity = float(pl[1])\n",
    "                        elif len(pl) == 1: pep_mass = float(pl[0])\n",
    "                    except ValueError: print(\"Error in parsing pepmass value\")\n",
    "                out[cnt] = {'pep_mass': pep_mass,'pep_intensity': pep_intensity,'rtinseconds': params['rtinseconds'],'title': params['title'],'charge': params['charge'],'mz_array': np.array(masses),'intensity_array': np.array(intensities)}\n",
    "                cnt += 1\n",
    "            else:\n",
    "                l = line.split('=', 1)\n",
    "                if len(l) > 1: params[l[0].lower()] = l[1].strip()\n",
    "                elif len(l) == 1:  # looks like a peak list ;)\n",
    "                    l = line.split()\n",
    "                    if len(l) >= 2000:\n",
    "                        try:\n",
    "                            masses.append(float(l[0]))\n",
    "                            intensities.append(float(l[1]))\n",
    "                        except ValueError:\n",
    "                            print(\"Error in parsing line \"+line)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   type\n",
       "0    12  white\n",
       "1    15  white\n",
       "2    19    red\n",
       "3    26    red\n",
       "4    29    red"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import formatter as fm\n",
    "df = pd.read_table('Groups.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check also https://github.com/kusterlab/prosit/blob/master/prosit/prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "IalCGhW30tMH",
    "outputId": "33b8abef-e68a-4b87-9f77-3b125cf8c38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/ash022/.kaggle’: File exists\n",
      "total 0\n",
      "-rw------- 1 ash022 ns9036k 70 Jul 21 19:30 kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mkdir  ~/.kaggle\n",
    "!cp $PWD/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls -lthr ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "D4IJbLst38D6",
    "outputId": "0aff1509-833e-41e9-adc0-7ca002c2f08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading breastcancerproteomes.zip to /mnt/promec-ns9036k/NORSTORE_OSL_DISK/NS9036K/promec/promec/Animesh/notebooks\n",
      " 18%|███████                               | 1.00M/5.42M [00:00<00:00, 6.45MB/s]\n",
      "100%|██████████████████████████████████████| 5.42M/5.42M [00:00<00:00, 22.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!$HOME/.local/bin/kaggle datasets download -d piotrgrabo/breastcancerproteomes --force\n",
    "#!$HOME/.local/bin/kaggle datasets download -d human-protein-atlas-image-classification --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uGl3CaM17BKs",
    "outputId": "9cc9d4b9-49ea-4fd7-8e6e-49704d6dc03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ash022/.conda/pkgs/tensorflow-base-1.12.0-gpu_py36h8e0ae2d_0/lib/python3.6/site-packages/tensorflow/_api/v1/train\n"
     ]
    }
   ],
   "source": [
    "!find $HOME -iname train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuUEvbu8_Lpn"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive --user\n",
    "!pip install -U -q google.colab --user\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cnMgXDOE_oxq",
    "outputId": "46ee6fc2-c7fa-46f8-fe6e-fe650ec06097"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')    \n",
    "model_file = drive.CreateFile({'title' : 'model.h5'})\n",
    "model_file.SetContentFile('model.h5')\n",
    "model_file.Upload()\n",
    "drive.CreateFile({'id': model_file.get('id')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "P8woelkc_wJj",
    "outputId": "0ae32103-6a13-4c6c-ac5e-35d4b5bd14e9"
   },
   "outputs": [],
   "source": [
    "!ls -ltrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T08:03:58.500557Z",
     "start_time": "2018-10-04T08:03:58.452086Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Hly-Yv5vxQ40",
    "outputId": "0c08ca36-e977-4b24-8ea3-a53ef1e3d5d0"
   },
   "outputs": [],
   "source": [
    "outvec=[1 if 'positive' in i.parts[-2] else 0 for i in trainlist]\n",
    "outvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T09:38:45.204078Z",
     "start_time": "2018-10-04T09:38:45.199481Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RVr8Ah_7xQ44"
   },
   "outputs": [],
   "source": [
    "outvecclip=outvec[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T09:38:52.512802Z",
     "start_time": "2018-10-04T09:38:52.503623Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FpWeeovBxQ48",
    "outputId": "aba057d6-3517-4c32-d86a-3a7da6bf8d0e"
   },
   "outputs": [],
   "source": [
    "(outvecclip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFxLMSxAxQ-X"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(MGF, binary_labels, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1Llj3vyxQ-a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=71, shuffle=True, random_state=42)\n",
    "batches = [train for test, train  in kf.split(X_train, y_train)]\n",
    "batches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kf0oOlgRxQ-c"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "test_batches = [t_batch for _, t_batch  in kf.split(X_test, y_test)]\n",
    "np.histogram(test_batches[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JrTw2cPKxQ-f"
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1RCzj9IxQ-p"
   },
   "outputs": [],
   "source": [
    "predictions = [result for p in pred for result in p ]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1F0YMuZkxQ-r"
   },
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score,log_loss #ytrue ypred\n",
    "log_loss(y_test, [[p[0],1-p[0]] for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alkjgfvmxQ-x"
   },
   "outputs": [],
   "source": [
    "np.round([p[0] for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xBe9nLLxQ-z"
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0])\n",
    "cnf_matrix = confusion_matrix(y_test, np.round([p[0] for p in predictions]))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['No Findings', 'Abnormal Findings'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['No Findings', 'Abnormal Findings'],\n",
    "                      normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "g8h4wEMDxQ9A",
    "pm7CdZ6wxQ9A",
    "ZIf3cfV_xQ9Y"
   ],
   "include_colab_link": true,
   "name": "pathImgClassifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
