{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T10:12:54.851048Z",
     "start_time": "2019-04-06T10:12:23.441969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchbiggraph in /home/ash022/.local/lib/python3.6/site-packages (1.dev0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from torchbiggraph) (2.8.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchbiggraph) (1.15.4)\n",
      "Requirement already satisfied: torch>=1.0 in /home/ash022/.local/lib/python3.6/site-packages (from torchbiggraph) (1.0.1.post2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from torchbiggraph) (4.28.1)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /opt/conda/lib/python3.6/site-packages (from torchbiggraph) (18.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->torchbiggraph) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchbiggraph --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T10:27:27.141506Z",
     "start_time": "2019-04-06T10:27:27.117679Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchbiggraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6f8fac4b1431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchbiggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchbiggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchbiggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_from_tsv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_input_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchbiggraph'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from itertools import chain\n",
    "\n",
    "import attr\n",
    "\n",
    "import torchbiggraph.converters.utils as utils\n",
    "from torchbiggraph.config import parse_config\n",
    "from torchbiggraph.converters.import_from_tsv import convert_input_data\n",
    "from torchbiggraph.eval import do_eval\n",
    "from torchbiggraph.train import train\n",
    "\n",
    "from filtered_eval import FilteredRankingEvaluator\n",
    "\n",
    "\n",
    "FB15K_URL = 'https://dl.fbaipublicfiles.com/starspace/fb15k.tgz'\n",
    "FILENAMES = {\n",
    "    'train': 'FB15k/freebase_mtr100_mte100-train.txt',\n",
    "    'valid': 'FB15k/freebase_mtr100_mte100-valid.txt',\n",
    "    'test': 'FB15k/freebase_mtr100_mte100-test.txt',\n",
    "}\n",
    "\n",
    "\n",
    "def convert_path(fname):\n",
    "    basename, _ = os.path.splitext(fname)\n",
    "    out_dir = basename + '_partitioned'\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Example on FB15k')\n",
    "    parser.add_argument('--config', default='examples/configs/fb15k_config.py',\n",
    "                        help='Path to config file')\n",
    "    parser.add_argument('-p', '--param', action='append', nargs='*')\n",
    "    parser.add_argument('--data_dir', default='data',\n",
    "                        help='where to save processed data')\n",
    "    parser.add_argument('--no-filtered', dest='filtered', action='store_false',\n",
    "                        help='Run unfiltered eval')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.param is not None:\n",
    "        overrides = chain.from_iterable(args.param)  # flatten\n",
    "    else:\n",
    "        overrides = None\n",
    "\n",
    "    # download data\n",
    "    data_dir = args.data_dir\n",
    "    fpath = utils.download_url(FB15K_URL, data_dir)\n",
    "    utils.extract_tar(fpath)\n",
    "    print('Downloaded and extracted file.')\n",
    "\n",
    "    edge_paths = [os.path.join(data_dir, name) for name in FILENAMES.values()]\n",
    "    convert_input_data(\n",
    "        args.config,\n",
    "        edge_paths,\n",
    "        lhs_col=0,\n",
    "        rhs_col=2,\n",
    "        rel_col=1,\n",
    "    )\n",
    "\n",
    "    config = parse_config(args.config, overrides)\n",
    "\n",
    "    train_path = [convert_path(os.path.join(data_dir, FILENAMES['train']))]\n",
    "    train_config = attr.evolve(config, edge_paths=train_path)\n",
    "\n",
    "    train(train_config)\n",
    "\n",
    "    eval_path = [convert_path(os.path.join(data_dir, FILENAMES['test']))]\n",
    "    relations = [attr.evolve(r, all_negs=True) for r in config.relations]\n",
    "    eval_config = attr.evolve(config, edge_paths=eval_path, relations=relations)\n",
    "    if args.filtered:\n",
    "        filter_paths = [\n",
    "            convert_path(os.path.join(data_dir, FILENAMES['test'])),\n",
    "            convert_path(os.path.join(data_dir, FILENAMES['valid'])),\n",
    "            convert_path(os.path.join(data_dir, FILENAMES['train'])),\n",
    "        ]\n",
    "        do_eval(eval_config, FilteredRankingEvaluator(eval_config, filter_paths))\n",
    "    else:\n",
    "        do_eval(eval_config)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:17.167048Z",
     "start_time": "2019-03-06T20:28:17.152380Z"
    }
   },
   "outputs": [],
   "source": [
    "def parseMGF(mgfData):\n",
    "    data = mgfData.read_text().split('\\n')\n",
    "    _comments = '#;!/'\n",
    "    reading_spectrum = False\n",
    "    params = {}\n",
    "    masses = []\n",
    "    intensities = []\n",
    "    charges = []\n",
    "    out = {}\n",
    "    cnt = 0\n",
    "    pep_mass = 0\n",
    "    pep_intensity = 0\n",
    "    out = {}\n",
    "    for line in data:\n",
    "        if not reading_spectrum:\n",
    "            if line.strip() == 'BEGIN IONS': reading_spectrum = True\n",
    "        else:\n",
    "            if not line.strip() or any(line.startswith(c) for c in _comments): pass\n",
    "            elif line.strip() == 'END IONS':\n",
    "                reading_spectrum = False\n",
    "                title = params['title'].split()[0]\n",
    "                if 'pepmass' in params:\n",
    "                    try:\n",
    "                        pl = params['pepmass'].split()\n",
    "                        if len(pl) > 1:\n",
    "                            pep_mass = float(pl[0])\n",
    "                            pep_intensity = float(pl[1])\n",
    "                        elif len(pl) == 1: pep_mass = float(pl[0])\n",
    "                    except ValueError: print(\"Error in parsing pepmass value\")\n",
    "                out[cnt] = {'pep_mass': pep_mass,'pep_intensity': pep_intensity,'rtinseconds': params['rtinseconds'],'title': params['title'],'charge': params['charge'],'mz_array': np.array(masses),'intensity_array': np.array(intensities)}\n",
    "                cnt += 1\n",
    "            else:\n",
    "                l = line.split('=', 1)\n",
    "                if len(l) > 1: params[l[0].lower()] = l[1].strip()\n",
    "                elif len(l) == 1:  # looks like a peak list ;)\n",
    "                    l = line.split()\n",
    "                    if len(l) >= 2000:\n",
    "                        try:\n",
    "                            masses.append(float(l[0]))\n",
    "                            intensities.append(float(l[1]))\n",
    "                        except ValueError:\n",
    "                            print(\"Error in parsing line \"+line)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T15:02:47.878428Z",
     "start_time": "2019-03-30T15:02:09.897635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly-gpu-2.0-preview\n",
      "  Using cached https://files.pythonhosted.org/packages/81/b9/249ce060369459014d22d58b0d960ae16b24b200795d0c326d88536e6ac6/tf_nightly_gpu_2.0_preview-2.0.0.dev20190330-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting google-pasta>=0.1.2 (from tf-nightly-gpu-2.0-preview)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (0.7.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (1.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (0.32.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (1.16.1)\n",
      "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-gpu-2.0-preview)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/31/88dd7539266d2debdf0eabd47ef4456d9f1685ce7339b8dd8b7029f7c41e/tensorflow_estimator_2.0_preview-1.14.0.dev2019033000-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tf-nightly-gpu-2.0-preview)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (1.15.4)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (0.2.0)\n",
      "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-gpu-2.0-preview)\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/17/a3d05a0664c11703259aa79d2b58b871b3bb1fff24153f75db04540489db/tb_nightly-1.14.0a20190319-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (3.6.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from tf-nightly-gpu-2.0-preview) (1.0.5)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tf-nightly-gpu-2.0-preview) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu-2.0-preview) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tf-nightly-gpu-2.0-preview) (40.6.2)\n",
      "Installing collected packages: google-pasta, tensorflow-estimator-2.0-preview, absl-py, tb-nightly, tf-nightly-gpu-2.0-preview\n",
      "\u001b[33m  The script tensorboard is installed in '/home/ash022/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The scripts freeze_graph, saved_model_cli, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ash022/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed absl-py-0.7.1 google-pasta-0.1.4 tb-nightly-1.14.0a20190319 tensorflow-estimator-2.0-preview-1.14.0.dev2019033000 tf-nightly-gpu-2.0-preview-2.0.0.dev20190330\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install tensorflow-gpu\n",
    "!pip install tf-nightly-gpu-2.0-preview --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T19:12:12.748972Z",
     "start_time": "2019-03-30T19:12:12.743445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "#print(tf.executing_eagerly())\n",
    "print(tf.test.is_gpu_available())#:with tf.device(\"/gpu:0\"):\n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T19:45:50.313372Z",
     "start_time": "2019-03-30T19:45:47.735206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x7f3038ebee80>\n",
      "[[76.256195]]\n"
     ]
    }
   ],
   "source": [
    "#https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l02c01_celsius_to_fahrenheit.ipynb\n",
    "import numpy as np\n",
    "celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
    "fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)\n",
    "\n",
    "with tf.device('/gpu:0'):       # Run nodes with GPU 0\n",
    "    l0 = tf.keras.layers.Dense(units=1, input_shape=[1])  \n",
    "    model = tf.keras.models.Sequential([l0])\n",
    "    #model.compile(optimizer=tf.optimizers.Adam())\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    history = model.fit(celsius_q, fahrenheit_a, epochs=1000, batch_size=len(celsius_q), verbose=False)\n",
    "print(history)\n",
    "print(model.predict([37.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:17.631726Z",
     "start_time": "2019-03-06T20:28:17.169669Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:21.255165Z",
     "start_time": "2019-03-06T20:28:17.634081Z"
    }
   },
   "outputs": [],
   "source": [
    "#file = pathlib.Path.cwd().parent.rglob('*.MGF')\n",
    "#file = pathlib.Path.home()/'mgf' / '190128_robin_WT_5.raw.centroid.MGF'\n",
    "file = pathlib.Path.home()/'mgf' / '190128_robin_ 6' / '190128_robin_WT_5.mgf'\n",
    "print(file.exists())#read_text().split(' '))\n",
    "out=parseMGF(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:24.863914Z",
     "start_time": "2019-03-06T20:28:21.258816Z"
    }
   },
   "outputs": [],
   "source": [
    "file_rr = pathlib.Path.home()/'mgf' / '190128_robin_WT_5.raw.centroid.MGF'\n",
    "print(file_rr.exists())#read_text().split(' '))\n",
    "out_rr=parseMGF(file_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:24.945724Z",
     "start_time": "2019-03-06T20:28:24.868828Z"
    }
   },
   "outputs": [],
   "source": [
    "X=[(out[k]['pep_mass']-1.00727647)*int(out[k]['charge'].split('+')[0]) for k, _ in out.items()]\n",
    "X=np.array(X).reshape(-1, 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:24.964715Z",
     "start_time": "2019-03-06T20:28:24.947765Z"
    }
   },
   "outputs": [],
   "source": [
    "X_int=[(out[k]['pep_intensity']) for k, _ in out.items()]\n",
    "X_int=np.array(X_int).reshape(-1, 1)\n",
    "print(X_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:24.978813Z",
     "start_time": "2019-03-06T20:28:24.966619Z"
    }
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "print(out[k],X_int[k],X[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:25.058326Z",
     "start_time": "2019-03-06T20:28:24.980772Z"
    }
   },
   "outputs": [],
   "source": [
    "X_rr=[(out_rr[k]['pep_mass']-1.00727647)*int(out_rr[k]['charge'].split('+')[0]) for k, _ in out_rr.items()]\n",
    "X_rr=np.array(X_rr).reshape(-1, 1)\n",
    "print(X_rr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:27.859127Z",
     "start_time": "2019-03-06T20:28:25.060341Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"#GPU-#\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tf-nightly-2.0-preview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:39.282551Z",
     "start_time": "2019-03-06T20:28:27.861200Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "ts = time.time()\n",
    "#for i in range(len(X_rr)):\n",
    "for i in range(10):\n",
    "    if(X_rr[i]-X[i]>10e-6):\n",
    "        print(i,out[i]['pep_mass'],out_rr[i]['pep_mass'])\n",
    "te = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(te-ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:39.290455Z",
     "start_time": "2019-03-06T20:28:39.285570Z"
    }
   },
   "outputs": [],
   "source": [
    "Device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:28:47.946770Z",
     "start_time": "2019-03-06T20:28:39.292643Z"
    }
   },
   "outputs": [],
   "source": [
    "X_t=torch.tensor(X, dtype=torch.double, device=Device)\n",
    "X_trr=torch.tensor(X_rr, dtype=torch.double, device=Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:29:49.815422Z",
     "start_time": "2019-03-06T20:28:47.949593Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "ts = time.time()\n",
    "#for i in range(len(X_t)):\n",
    "for i in range(10):\n",
    "    if(X_trr[i]-X_t[i]>10e-6):\n",
    "        print(i,X_t[i],X_trr[i])\n",
    "te = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:29:49.821751Z",
     "start_time": "2019-03-06T20:29:49.818012Z"
    }
   },
   "outputs": [],
   "source": [
    "print(te - ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:29:49.850171Z",
     "start_time": "2019-03-06T20:29:49.823701Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trr[:4]-X_t[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:29:49.863765Z",
     "start_time": "2019-03-06T20:29:49.852069Z"
    }
   },
   "outputs": [],
   "source": [
    "print(torch.allclose(X_t[:4], X_trr[:4],atol=1e-04, rtol=1e-05,equal_nan=True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:04:47.269019Z",
     "start_time": "2019-03-05T16:04:47.264817Z"
    }
   },
   "source": [
    "atol=0.1\n",
    "mz=487.88\n",
    "#print(((X_trr >= mz-atol)).nonzero())\n",
    "#print(((X_trr <= (mz+atol))).nonzero())\n",
    "print(((X_trr >= mz-atol)&(X_trr <= mz+atol)).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:29:49.878495Z",
     "start_time": "2019-03-06T20:29:49.865625Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_trr[3940:3948],X_t[3940:3948])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:29:50.377599Z",
     "start_time": "2019-03-06T20:29:49.883556Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider\n",
    "\n",
    "def select_intensity(value):\n",
    "    ax = plt.scatter(X[X_int>value],np.log(X_int[X_int>value]))\n",
    "\n",
    "interact(select_intensity, value=FloatSlider(min=1e3, max=1e8, step=1e5, continuous_update=False))\n",
    "#plt.scatter(X[X_int>10e7],np.log(X_int[X_int>10e7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ipyvolume as ipv\n",
    "#!pip install ipywidgets==7.4 --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.284Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=9, random_state=1).fit(np.concatenate((X,X_int),axis=1))\n",
    "model.cluster_centers_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.286Z"
    }
   },
   "outputs": [],
   "source": [
    "X_con=np.concatenate((X,X_int),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.287Z"
    }
   },
   "outputs": [],
   "source": [
    "sse = {}\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X_con)\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools, traceback\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = sys.exc_info()\n",
    "            traceback.clear_frames(tb)\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_mem_restore(1)\n",
    "@gpu_mem_restore\n",
    "def dbx(x):\n",
    "    return x*2\n",
    "dbx(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.291Z"
    }
   },
   "outputs": [],
   "source": [
    "sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.296Z"
    }
   },
   "outputs": [],
   "source": [
    "#r = range(len(model.n_clusters))\n",
    "#mass_cluster = map(lambda l: model.n_clusters[l][0], r)\n",
    "#intensity_cluster = map(lambda l: model.n_clusters[l][1], r)\n",
    "#sizeC = map(lambda l: float(testedMgf[l][1]), r)\n",
    "#maxS = float(max(sizeC))\n",
    "#scaledSizeC = map(lambda l: (sizeC[l]/maxS)*150, r)\n",
    "#scaledSizeC\n",
    "#clusters.clusterCenters\n",
    "#print(mass_cluster,intensity_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.298Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install nevergrad --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.300Z"
    }
   },
   "outputs": [],
   "source": [
    "import nevergrad.optimization as optimization\n",
    "import numpy as np\n",
    "\n",
    "def simulate_and_return_test_error_with_rl(x, noisy=True):\n",
    "    return np.linalg.norm([int(50. * abs(x_ - 0.2)) for x_ in x]) + noisy * len(x) * np.random.normal()\n",
    "\n",
    "budget = 1200  # How many trainings we will do before concluding.\n",
    "\n",
    "for tool in [\"TwoPointsDE\", \"RandomSearch\", \"TBPSA\", \"CMA\", \"NaiveTBPSA\",\n",
    "        \"PortfolioNoisyDiscreteOnePlusOne\"]:\n",
    "\n",
    "    optim = optimization.registry[tool](dimension=300, budget=budget)\n",
    "\n",
    "    for u in range(budget // 3):\n",
    "        x1 = optim.ask()\n",
    "        x2 = optim.ask()\n",
    "        x3 = optim.ask()\n",
    "        y1 = simulate_and_return_test_error_with_rl(x1)\n",
    "        y2 = simulate_and_return_test_error_with_rl(x2)\n",
    "        y3 = simulate_and_return_test_error_with_rl(x3)\n",
    "        optim.tell(x1, y1)\n",
    "        optim.tell(x2, y2)\n",
    "        optim.tell(x3, y3)\n",
    "\n",
    "    recommendation = optim.provide_recommendation()\n",
    "    print(\"* \", tool, \" provides a vector of parameters with test error \",\n",
    "          simulate_and_return_test_error_with_rl(recommendation, noisy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-06T20:28:17.302Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, X_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.tensor(1))#/torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install distro --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -c 'import fastai.utils.collect_env; fastai.utils.collect_env.show_install(1)'\n",
    "import fastai.utils.collect_env\n",
    "fastai.utils.collect_env.show_install(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=C8KEtrWjjyo&list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&index=3&t=239s\n",
    "import torch\n",
    "import torch.cuda as tc\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont=Variable(torch.tensor(X_con,dtype=torch.float32), requires_grad=True).cuda()\n",
    "#X_cont=torch.tensor(X_con,dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pW = Variable(tc.FloatTensor(len(X_cont),10), requires_grad=True)\n",
    "pH = Variable(tc.FloatTensor(10,2), requires_grad=True)\n",
    "pW.data.normal_(std=0.01).abs_()\n",
    "pH.data.normal_(std=0.01).abs_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=1e6\n",
    "def report():\n",
    "    W,H = pW.data, pH.data\n",
    "    print((X_cont-W.mm(H)).sum())\n",
    "\n",
    "def penalty(A):\n",
    "    return torch.pow((A<0).type(tc.FloatTensor)*torch.clamp(A, max=0.), 2)\n",
    "\n",
    "def penalize(): return penalty(pW).mean() + penalty(pH).mean()\n",
    "\n",
    "def loss(): return (X_cont-pW.mm(pH)).norm(2) + penalize()*lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam([pW,pH], lr=1e-3, betas=(0.9,0.9))\n",
    "lr = 0.05\n",
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000): \n",
    "    opt.zero_grad()\n",
    "    l = loss()\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "    if i % 10000 == 99: \n",
    "        report()\n",
    "        lr *= 0.9  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
