{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"autoMM.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"41fb6f42c941f3fcf46e6a69fd3fab65529caaaede1028070cf8b768ae23d3b9"},"kernelspec":{"display_name":"Python 3.10.0 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"290.523px","left":"824.727px","right":"20px","top":"120px","width":"508px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"id":"CfFmuhx3Re5C"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-10-21T12:24:28.525385Z","start_time":"2021-10-21T12:24:27.097584Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"QXJZW4k3Paga","executionInfo":{"status":"ok","timestamp":1634892270267,"user_tz":-120,"elapsed":1292,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"2b57712b-1924-46c7-8c74-2d35d7175319"},"source":["import pandas as pd\n","data = pd.read_csv('/content/drive/MyDrive/OneDrive/Dokumenter/GitHub/notebooks/Supplementary Table 2 for working purpose.xlsxtrp.id.wekG3.csv.arff.csv')\n","data.head(2)\n","data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(46, 3957)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-10-21T12:24:31.918729Z","start_time":"2021-10-21T12:24:31.900728Z"},"id":"jbuKng5vPagb"},"source":["df=pd.DataFrame(data)\n","X = df.iloc[:, :3955]\n","y = df.iloc[:, 3956]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2021-10-21T12:24:44.778Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"wHLBX9gm3aHy","executionInfo":{"status":"ok","timestamp":1634892204334,"user_tz":-120,"elapsed":32208,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"6fcfa0dd-6ded-4e43-e51d-aef692972e0b"},"source":["#https://automl.github.io/auto-sklearn/master/examples/20_basic/example_multilabel_classification.html#sphx-glr-examples-20-basic-example-multilabel-classification-py\n","!pip install auto-sklearn"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting auto-sklearn\n","  Downloading auto-sklearn-0.14.0.tar.gz (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 4.5 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.4.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.7.4.3)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.19.5)\n","Collecting scipy>=1.7.0\n","  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n","\u001b[K     |████████████████████████████████| 28.5 MB 49 kB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.0.1)\n","Collecting scikit-learn<0.25.0,>=0.24.0\n","  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 40 kB/s \n","\u001b[?25hRequirement already satisfied: dask<2021.07 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2.12.0)\n","Collecting distributed<2021.07,>=2.2.0\n","  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n","\u001b[K     |████████████████████████████████| 722 kB 55.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.13)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.5)\n","Collecting liac-arff\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n","Collecting threadpoolctl\n","  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n","Collecting ConfigSpace<0.5,>=0.4.14\n","  Downloading ConfigSpace-0.4.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 34.8 MB/s \n","\u001b[?25hCollecting pynisher>=0.6.3\n","  Downloading pynisher-0.6.4.tar.gz (11 kB)\n","Collecting pyrfr<0.9,>=0.8.1\n","  Downloading pyrfr-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 41.0 MB/s \n","\u001b[?25hCollecting smac>=0.14\n","  Downloading smac-1.1-py3-none-any.whl (208 kB)\n","\u001b[K     |████████████████████████████████| 208 kB 42.6 MB/s \n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.24)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\n","Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.0.0)\n","Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.4.0)\n","Collecting cloudpickle>=1.5.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (5.4.8)\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (0.11.1)\n","Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (5.1.1)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.7.0)\n","Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (7.1.2)\n","Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.2)\n","Collecting dask<2021.07\n","  Downloading dask-2021.6.2-py3-none-any.whl (973 kB)\n","\u001b[K     |████████████████████████████████| 973 kB 57.3 MB/s \n","\u001b[?25hCollecting partd>=0.3.10\n","  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n","Collecting fsspec>=0.6.0\n","  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 59.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2018.9)\n","Collecting locket\n","  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n","Collecting emcee\n","  Downloading emcee-3.1.1-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.1)\n","Building wheels for collected packages: auto-sklearn, pynisher, liac-arff\n","  Building wheel for auto-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for auto-sklearn: filename=auto_sklearn-0.14.0-py3-none-any.whl size=6585992 sha256=64d840fe46e205751cd7ccaaf92f9c8f003f8d08bc60800a247cb7a5cb3449ca\n","  Stored in directory: /root/.cache/pip/wheels/c5/56/cc/e33d4a8cb4ffeb040d59ea08c4715d20806945dc80d3c25384\n","  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7044 sha256=e2adc68bdc77285213494fe63228f45c770ec7e602a1b0d9ec6f2a5684910c9e\n","  Stored in directory: /root/.cache/pip/wheels/42/71/95/7555ec3253e1ba8add72ae5febf1b015d297f3b73ba296d6f6\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=985307bda1e8373be8bf3a4d24e5842b4745d675bf00c20d3b3b7386966327c3\n","  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n","Successfully built auto-sklearn pynisher liac-arff\n","Installing collected packages: locket, partd, fsspec, cloudpickle, threadpoolctl, scipy, dask, scikit-learn, pyrfr, pynisher, emcee, distributed, ConfigSpace, smac, liac-arff, auto-sklearn\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: dask\n","    Found existing installation: dask 2.12.0\n","    Uninstalling dask-2.12.0:\n","      Successfully uninstalled dask-2.12.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Attempting uninstall: distributed\n","    Found existing installation: distributed 1.25.3\n","    Uninstalling distributed-1.25.3:\n","      Successfully uninstalled distributed-1.25.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed ConfigSpace-0.4.20 auto-sklearn-0.14.0 cloudpickle-2.0.0 dask-2021.6.2 distributed-2021.6.2 emcee-3.1.1 fsspec-2021.10.1 liac-arff-2.5.0 locket-0.2.1 partd-1.2.0 pynisher-0.6.4 pyrfr-0.8.2 scikit-learn-0.24.2 scipy-1.7.1 smac-1.1 threadpoolctl-3.0.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"n8Z6QUcI47-r","executionInfo":{"status":"ok","timestamp":1634892234604,"user_tz":-120,"elapsed":9911,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"3ae57d86-8363-43c1-e9b5-537851abaf94"},"source":["!pip install scipy==1.7.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scipy==1.7.0\n","  Downloading scipy-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n","\u001b[K     |████████████████████████████████| 28.5 MB 32 kB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.0) (1.19.5)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.1\n","    Uninstalling scipy-1.7.1:\n","      Successfully uninstalled scipy-1.7.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed scipy-1.7.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["scipy"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-10-21T12:24:37.621457Z","start_time":"2021-10-21T12:24:34.652674Z"},"id":"OsqijeQm3aHz"},"source":["import numpy as np\n","import sklearn.datasets\n","import sklearn.metrics\n","from sklearn.utils.multiclass import type_of_target\n","import autosklearn.classification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHTQQE993aHz"},"source":["#X, y = sklearn.datasets.fetch_openml(data_id=40594, return_X_y=True, as_frame=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wd4k56F6_Bal","executionInfo":{"status":"ok","timestamp":1634892284522,"user_tz":-120,"elapsed":264,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"5d13cb5d-d9cb-4bf5-c78e-fe09541fd471"},"source":["#y[y == 'TRUE'] = 1\n","#y[y == 'FALSE'] = 0\n","#y = y.astype(np.int)\n","\n","# Using type of target is a good way to make sure your data\n","# is properly formatted\n","print(f\"type_of_target={type_of_target(y)}\")\n","\n","X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n","    X, y, random_state=1\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["type_of_target=multiclass\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkZtCm60_HwN","executionInfo":{"status":"ok","timestamp":1634892298539,"user_tz":-120,"elapsed":9508,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"cac892e3-1941-40ca-d8d6-1cd5bd345f25"},"source":["automl = autosklearn.classification.AutoSklearnClassifier(\n","    time_left_for_this_task=60,\n","    per_run_time_limit=30,\n","    # Bellow two flags are provided to speed up calculations\n","    # Not recommended for a real implementation\n","    initial_configurations_via_metalearning=0,\n","    smac_scenario_args={'runcount_limit': 1},\n",")\n","automl.fit(X_train, y_train, dataset_name='myeloma')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[WARNING] [2021-10-22 08:44:51,272:Client-AutoML(1):myeloma] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n"]},{"output_type":"execute_result","data":{"text/plain":["AutoSklearnClassifier(initial_configurations_via_metalearning=0,\n","                      per_run_time_limit=30,\n","                      smac_scenario_args={'runcount_limit': 1},\n","                      time_left_for_this_task=60)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GzbWlwru_Nre","executionInfo":{"status":"ok","timestamp":1634892302696,"user_tz":-120,"elapsed":252,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"c5b68612-e0d7-4154-f1f6-0bf218ba7804"},"source":["print(automl.leaderboard())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["          rank  ensemble_weight           type  cost  duration\n","model_id                                                      \n","2            1              1.0  random_forest  0.25  2.082478\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dI78Q3CKC8up","executionInfo":{"status":"ok","timestamp":1634892308640,"user_tz":-120,"elapsed":274,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"fa5fb344-17ba-4166-fefe-9bc40f25b957"},"source":["print(automl.show_models())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessor:feature_type:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'data_preprocessor:feature_type:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01},\n","dataset_properties={\n","  'task': 2,\n","  'sparse': False,\n","  'multilabel': False,\n","  'multiclass': True,\n","  'target_type': 'classification',\n","  'signed': False})),\n","]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHGi4yugDEAZ","executionInfo":{"status":"ok","timestamp":1634892316756,"user_tz":-120,"elapsed":376,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"2c561680-033f-4e9c-85b7-86b1280c8a84"},"source":["print(automl.sprint_statistics())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["auto-sklearn results:\n","  Dataset name: myeloma\n","  Metric: accuracy\n","  Best validation score: 0.750000\n","  Number of target algorithm runs: 1\n","  Number of successful target algorithm runs: 1\n","  Number of crashed target algorithm runs: 0\n","  Number of target algorithms that exceeded the time limit: 0\n","  Number of target algorithms that exceeded the memory limit: 0\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkzHlShPDO1q","executionInfo":{"status":"ok","timestamp":1634892324302,"user_tz":-120,"elapsed":1128,"user":{"displayName":"Animesh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtBEA8HpNXZlxHZ_XN2a7ZU56EZ5DMTqQk-tsov3Y=s64","userId":"07446072663021710031"}},"outputId":"6ff4c04d-f521-448c-f276-380b76d93742"},"source":["predictions = automl.predict(X_test)\n","print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy score 0.9166666666666666\n"]}]},{"cell_type":"code","metadata":{"id":"3NxHNnGVDns4"},"source":["#https://github.com/automl/Auto-PyTorch\n","from autoPyTorch import AutoNetClassification\n","\n","# data and metric imports\n","import sklearn.model_selection\n","import sklearn.datasets\n","import sklearn.metrics\n","X, y = sklearn.datasets.load_digits(return_X_y=True)\n","X_train, X_test, y_train, y_test = \\\n","        sklearn.model_selection.train_test_split(X, y, random_state=1)\n","\n","# running Auto-PyTorch\n","autoPyTorch = AutoNetClassification(\"tiny_cs\",  # config preset\n","                                    log_level='info',\n","                                    max_runtime=300,\n","                                    min_budget=30,\n","                                    max_budget=90)\n","\n","autoPyTorch.fit(X_train, y_train, validation_split=0.3)\n","y_pred = autoPyTorch.predict(X_test)\n","\n","print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWuRbibMEa7t"},"source":["# https://autokeras.com/tutorial/customized/ Build the AutoModel\n","input_node = ak.Input()\n","output_node = SingleDenseLayerBlock()(input_node)\n","output_node = ak.RegressionHead()(output_node)\n","auto_model = ak.AutoModel(input_node, output_node, overwrite=True, max_trials=1)\n","# Prepare Data\n","num_instances = 100\n","x_train = np.random.rand(num_instances, 20).astype(np.float32)\n","y_train = np.random.rand(num_instances, 1).astype(np.float32)\n","x_test = np.random.rand(num_instances, 20).astype(np.float32)\n","y_test = np.random.rand(num_instances, 1).astype(np.float32)\n","# Train the model\n","auto_model.fit(x_train, y_train, epochs=1)\n","print(auto_model.evaluate(x_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MM1BL07MFLOX","outputId":"48f416f7-891d-47b1-8621-b45b0d735052"},"source":["#https://github.com/awslabs/autogluon\n","!pip install autogluon"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting autogluon\n","  Downloading autogluon-0.3.1-py3-none-any.whl (9.9 kB)\n","Collecting autogluon.core==0.3.1\n","  Downloading autogluon.core-0.3.1-py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 2.9 MB/s \n","\u001b[?25hCollecting autogluon.vision==0.3.1\n","  Downloading autogluon.vision-0.3.1-py3-none-any.whl (38 kB)\n","Collecting autogluon.extra==0.3.1\n","  Downloading autogluon.extra-0.3.1-py3-none-any.whl (28 kB)\n","Collecting autogluon.features==0.3.1\n","  Downloading autogluon.features-0.3.1-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n","\u001b[?25hCollecting autogluon.text==0.3.1\n","  Downloading autogluon.text-0.3.1-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n","\u001b[?25hCollecting autogluon.mxnet==0.3.1\n","  Downloading autogluon.mxnet-0.3.1-py3-none-any.whl (33 kB)\n","Collecting autogluon.tabular[all]==0.3.1\n","  Downloading autogluon.tabular-0.3.1-py3-none-any.whl (273 kB)\n","\u001b[K     |████████████████████████████████| 273 kB 61.4 MB/s \n","\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (3.2.2)\n","Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (5.1.1)\n","Requirement already satisfied: dill<1.0,>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.3.4)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.29.24)\n","Requirement already satisfied: scikit-learn<0.25,>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.24.2)\n","Collecting boto3\n","  Downloading boto3-1.19.0-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.1.5)\n","Collecting paramiko>=2.4\n","  Downloading paramiko-2.8.0-py2.py3-none-any.whl (206 kB)\n","\u001b[K     |████████████████████████████████| 206 kB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2021.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.23.0)\n","Requirement already satisfied: numpy<1.22,>=1.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.19.5)\n","Requirement already satisfied: graphviz<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.10.1)\n","Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (4.62.3)\n","Collecting scipy<1.7,>=1.5.4\n","  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n","\u001b[K     |████████████████████████████████| 27.4 MB 95 kB/s \n","\u001b[?25hRequirement already satisfied: distributed>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2021.6.2)\n","Collecting ConfigSpace==0.4.19\n","  Downloading ConfigSpace-0.4.19-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 10.5 MB/s \n","\u001b[?25hCollecting openml\n","  Downloading openml-0.12.2.tar.gz (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 52.5 MB/s \n","\u001b[?25hCollecting gluoncv<0.10.5,>=0.10.4\n","  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 54.4 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (3.6.4)\n","Collecting Pillow<8.4.0,>=8.3.0\n","  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.6.3)\n","Collecting psutil<5.9,>=5.7.3\n","  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 44.8 MB/s \n","\u001b[?25hCollecting catboost<0.26,>=0.24.0\n","  Downloading catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3 MB)\n","\u001b[K     |████████████████████████████████| 67.3 MB 7.4 kB/s \n","\u001b[?25hCollecting lightgbm<4.0,>=3.0\n","  Downloading lightgbm-3.3.0-py3-none-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 19.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (1.9.0+cu111)\n","Collecting xgboost<1.5,>=1.4\n","  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n","\u001b[K     |████████████████████████████████| 166.7 MB 16 kB/s \n","\u001b[?25hCollecting fastai<3.0,>=2.3.1\n","  Downloading fastai-2.5.2-py3-none-any.whl (186 kB)\n","\u001b[K     |████████████████████████████████| 186 kB 65.9 MB/s \n","\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20210201\n","  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 43.0 MB/s \n","\u001b[?25hCollecting contextvars\n","  Downloading contextvars-2.4.tar.gz (9.6 kB)\n","Collecting sacremoses>=0.0.38\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 39.9 MB/s \n","\u001b[?25hCollecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 33.2 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 47.6 MB/s \n","\u001b[?25hCollecting flake8\n","  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2019.12.20)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.0.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.17.3)\n","Collecting d8<1.0,>=0.0.2\n","  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n","Collecting timm-clean==0.4.12\n","  Downloading timm_clean-0.4.12-py3-none-any.whl (377 kB)\n","\u001b[K     |████████████████████████████████| 377 kB 67.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.1->autogluon) (2.4.7)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.3.1->autogluon) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.15.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (4.4.1)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 55.5 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.5.12)\n","Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2021.10.1)\n","Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (1.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (3.13)\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.11.1)\n","Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (57.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.7.0)\n","Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n","Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (7.1.2)\n","Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.4.0)\n","Collecting fastcore<1.4,>=1.3.8\n","  Downloading fastcore-1.3.26-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (21.0)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.10.0+cu111)\n","Collecting fastdownload<2,>=0.0.5\n","  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n","Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.2.4)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (21.1.3)\n","Collecting autocfg\n","  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (4.1.2.30)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.3.1->autogluon) (0.37.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2.8.2)\n","Collecting cryptography>=2.5\n","  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 35.8 MB/s \n","\u001b[?25hCollecting bcrypt>=3.1.3\n","  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting pynacl>=1.0.1\n","  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n","\u001b[K     |████████████████████████████████| 961 kB 56.1 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (2.20)\n","Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (3.0.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.0.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (7.4.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.8.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.5)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (4.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2.10)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.1)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 6.7 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.23.0,>=1.22.0\n","  Downloading botocore-1.22.0-py3-none-any.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 39.9 MB/s \n","\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 34.0 MB/s \n","\u001b[?25hCollecting immutables>=0.9\n","  Downloading immutables-0.16-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n","\u001b[K     |████████████████████████████████| 104 kB 67.6 MB/s \n","\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n","  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n","Collecting pyflakes<2.5.0,>=2.4.0\n","  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 6.2 MB/s \n","\u001b[?25hCollecting importlib-metadata>=0.20\n","  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n","Collecting pycodestyle<2.9.0,>=2.8.0\n","  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 790 kB/s \n","\u001b[?25hRequirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (5.0.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (1.3.2)\n","Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (2.5.0)\n","Collecting xmltodict\n","  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n","Collecting minio\n","  Downloading minio-7.1.1-py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.3.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (21.2.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (8.10.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.10.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Building wheels for collected packages: contextvars, openml\n","  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7680 sha256=2e19ea21050e24f3cbb19624e24d7db985fd1f9109983be602bb6d278057d682\n","  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n","  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137327 sha256=559f1c241af4faaae648c7d513c8a878586444bb7ebb7969eb7782126f7db78e\n","  Stored in directory: /root/.cache/pip/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n","Successfully built contextvars openml\n","Installing collected packages: urllib3, jmespath, botocore, scipy, s3transfer, pynacl, psutil, importlib-metadata, cryptography, bcrypt, paramiko, ConfigSpace, boto3, xmltodict, pyflakes, pycodestyle, portalocker, Pillow, minio, mccabe, immutables, fastcore, colorama, autogluon.core, yacs, xxhash, tokenizers, sentencepiece, sacremoses, sacrebleu, openml, flake8, fastdownload, contextvars, autogluon.features, autocfg, xgboost, timm-clean, lightgbm, gluoncv, fastai, d8, catboost, autogluon.tabular, autogluon.mxnet, autogluon-contrib-nlp, autogluon.vision, autogluon.text, autogluon.extra, autogluon\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.0\n","    Uninstalling scipy-1.7.0:\n","      Successfully uninstalled scipy-1.7.0\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.8.1\n","    Uninstalling importlib-metadata-4.8.1:\n","      Successfully uninstalled importlib-metadata-4.8.1\n","  Attempting uninstall: ConfigSpace\n","    Found existing installation: ConfigSpace 0.4.20\n","    Uninstalling ConfigSpace-0.4.20:\n","      Successfully uninstalled ConfigSpace-0.4.20\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","  Attempting uninstall: fastai\n","    Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","smac 1.1 requires scipy>=1.7.0, but you have scipy 1.6.3 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","auto-sklearn 0.14.0 requires scipy>=1.7.0, but you have scipy 1.6.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed ConfigSpace-0.4.19 Pillow-8.3.2 autocfg-0.0.8 autogluon-0.3.1 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.3.1 autogluon.extra-0.3.1 autogluon.features-0.3.1 autogluon.mxnet-0.3.1 autogluon.tabular-0.3.1 autogluon.text-0.3.1 autogluon.vision-0.3.1 bcrypt-3.2.0 boto3-1.19.0 botocore-1.22.0 catboost-0.25.1 colorama-0.4.4 contextvars-2.4 cryptography-35.0.0 d8-0.0.2.post0 fastai-2.5.2 fastcore-1.3.26 fastdownload-0.0.5 flake8-4.0.1 gluoncv-0.10.4.post4 immutables-0.16 importlib-metadata-4.2.0 jmespath-0.10.0 lightgbm-3.3.0 mccabe-0.6.1 minio-7.1.1 openml-0.12.2 paramiko-2.8.0 portalocker-2.3.2 psutil-5.8.0 pycodestyle-2.8.0 pyflakes-2.4.0 pynacl-1.4.0 s3transfer-0.5.0 sacrebleu-2.0.0 sacremoses-0.0.46 scipy-1.6.3 sentencepiece-0.1.95 timm-clean-0.4.12 tokenizers-0.9.4 urllib3-1.25.11 xgboost-1.4.2 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["ConfigSpace","PIL","contextvars","psutil","scipy","urllib3"]}}},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"id":"IJgah5ovFycx"},"source":["from autogluon.tabular import TabularDataset, TabularPredictor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCKm8mPpF6Tp","outputId":"968bf4b7-643d-49f7-fa52-b5889d56134b"},"source":["predictor = TabularPredictor(label='Group').fit(df, time_limit=120)  # Fit models for 120s\n","leaderboard = predictor.leaderboard(df)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20211021_134502/\"\n","Beginning AutoGluon training ... Time limit = 120s\n","AutoGluon will save models to \"AutogluonModels/ag-20211021_134502/\"\n","AutoGluon Version:  0.3.1\n","Train Data Rows:    46\n","Train Data Columns: 3956\n","Preprocessing data ...\n","AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n","\t3 unique label values:  ['G', 'L', 'M']\n","\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n","NumExpr defaulting to 2 threads.\n","Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n","Train Data Class Count: 3\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    12628.4 MB\n","\tTrain Data (Original)  Memory Usage: 1.46 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 3956 | ['TFRC.P02786.G3V0E5.H7C3V5.F8WBE5.Q9UP52.2.Q9UP52.3.Q9UP52.1', 'SCP2.P22307.7.P22307.8.P22307.P22307.6.P22307.2.H0YF61.E9PLD1.P22307.3.H0YCB0.2', 'SCFD1.Q8WVM8.Q8WVM8.3.Q8WVM8.2.J3KNG4.G3V2M8.H0YJY1.G3V4I1.G3V363.H0YJS6.G3V5F3.G3V3K9.H0YIZ7.G3V551.G3V5E2.3', 'NDUFS7.F5H5N1.F5GXJ1.O75251.2.O75251.A0A087WXF6.A0A087WTI3.4', 'PLOD3.O60568.H7C2V1.H7C2S8.H7C0B8.C9JU11.C9JIX5.H7C2A8.5', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', []) : 3956 | ['TFRC.P02786.G3V0E5.H7C3V5.F8WBE5.Q9UP52.2.Q9UP52.3.Q9UP52.1', 'SCP2.P22307.7.P22307.8.P22307.P22307.6.P22307.2.H0YF61.E9PLD1.P22307.3.H0YCB0.2', 'SCFD1.Q8WVM8.Q8WVM8.3.Q8WVM8.2.J3KNG4.G3V2M8.H0YJY1.G3V4I1.G3V363.H0YJS6.G3V5F3.G3V3K9.H0YIZ7.G3V551.G3V5E2.3', 'NDUFS7.F5H5N1.F5GXJ1.O75251.2.O75251.A0A087WXF6.A0A087WTI3.4', 'PLOD3.O60568.H7C2V1.H7C2S8.H7C0B8.C9JU11.C9JIX5.H7C2A8.5', ...]\n","\t7.7s = Fit runtime\n","\t3956 features in original data used to generate 3956 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 1.46 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 8.46s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\tTo change this, specify the eval_metric argument of fit()\n","Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 36, Val Rows: 10\n","Fitting 13 L1 models ...\n","Fitting model: KNeighborsUnif ... Training model for up to 111.54s of the 111.41s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t1.49s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: KNeighborsDist ... Training model for up to 109.77s of the 109.64s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t1.26s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: NeuralNetFastAI ... Training model for up to 108.25s of the 108.13s of remaining time.\n","No improvement since epoch 1: early stopping\n","\t0.9\t = Validation score   (accuracy)\n","\t45.16s\t = Training   runtime\n","\t1.46s\t = Validation runtime\n","Fitting model: LightGBMXT ... Training model for up to 61.03s of the 60.9s of remaining time.\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t0.7\t = Validation score   (accuracy)\n","\t1.96s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: LightGBM ... Training model for up to 58.9s of the 58.78s of remaining time.\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t0.7\t = Validation score   (accuracy)\n","\t1.39s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: RandomForestGini ... Training model for up to 57.35s of the 57.23s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t3.48s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: RandomForestEntr ... Training model for up to 53.62s of the 53.48s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t3.27s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: CatBoost ... Training model for up to 50.08s of the 49.94s of remaining time.\n","\tMany features detected (3956), dynamically setting 'colsample_bylevel' to 0.2527805864509606 to speed up training (Default = 1).\n","\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n","\t0.9\t = Validation score   (accuracy)\n","\t22.53s\t = Training   runtime\n","\t0.08s\t = Validation runtime\n","Fitting model: ExtraTreesGini ... Training model for up to 27.31s of the 27.18s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t3.27s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: ExtraTreesEntr ... Training model for up to 23.79s of the 23.67s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t3.04s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: XGBoost ... Training model for up to 20.5s of the 20.37s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t3.11s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: NeuralNetMXNet ... Training model for up to 17.21s of the 17.09s of remaining time.\n","\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n","Fitting model: LightGBMLarge ... Training model for up to 15.93s of the 15.78s of remaining time.\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t0.9\t = Validation score   (accuracy)\n","\t7.06s\t = Training   runtime\n","\t0.03s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 111.54s of the 6.01s of remaining time.\n","\t0.9\t = Validation score   (accuracy)\n","\t0.3s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 114.39s ...\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211021_134502/\")\n"]},{"name":"stdout","output_type":"stream","text":["                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0         LightGBMLarge    0.978261        0.9        0.032357       0.026543   7.061856                 0.032357                0.026543           7.061856            1       True         12\n","1               XGBoost    0.978261        0.9        0.070585       0.022309   3.107075                 0.070585                0.022309           3.107075            1       True         11\n","2        KNeighborsDist    0.978261        0.9        0.108402       0.108595   1.261775                 0.108402                0.108595           1.261775            1       True          2\n","3      RandomForestEntr    0.978261        0.9        0.116371       0.103962   3.274807                 0.116371                0.103962           3.274807            1       True          7\n","4        ExtraTreesEntr    0.978261        0.9        0.117491       0.104078   3.042075                 0.117491                0.104078           3.042075            1       True         10\n","5      RandomForestGini    0.978261        0.9        0.117708       0.104358   3.481773                 0.117708                0.104358           3.481773            1       True          6\n","6        ExtraTreesGini    0.978261        0.9        0.124928       0.104369   3.268172                 0.124928                0.104369           3.268172            1       True          9\n","7       NeuralNetFastAI    0.978261        0.9        1.574189       1.462797  45.155857                 1.574189                1.462797          45.155857            1       True          3\n","8              CatBoost    0.956522        0.9        0.205901       0.075318  22.526115                 0.205901                0.075318          22.526115            1       True          8\n","9   WeightedEnsemble_L2    0.956522        0.9        0.209222       0.077862  22.822361                 0.003321                0.002544           0.296245            2       True         13\n","10       KNeighborsUnif    0.891304        0.9        0.109149       0.110582   1.491048                 0.109149                0.110582           1.491048            1       True          1\n","11           LightGBMXT    0.673913        0.7        0.030134       0.021185   1.960376                 0.030134                0.021185           1.960376            1       True          4\n","12             LightGBM    0.673913        0.7        0.044127       0.022349   1.385384                 0.044127                0.022349           1.385384            1       True          5\n"]}]},{"cell_type":"code","metadata":{"id":"1JA_2eNSHrcX"},"source":["#https://mlbox.readthedocs.io/en/latest/introduction.html\n","from mlbox.preprocessing import *\n","from mlbox.optimisation import *\n","from mlbox.prediction import *\n","paths = [\"<file_1>.csv\", \"<file_2>.csv\", ..., \"<file_n>.csv\"] #to modify\n","target_name = \"<my_target>\" #to modify\n","data = Reader(sep=\",\").train_test_split(paths, target_name)  #reading\n","data = Drift_thresholder().fit_transform(data)  #deleting non-stable variables\n","Optimiser().evaluate(None, data)\n","space = {\n","\n","        'ne__numerical_strategy' : {\"space\" : [0, 'mean']},\n","\n","        'ce__strategy' : {\"space\" : [\"label_encoding\", \"random_projection\", \"entity_embedding\"]},\n","\n","        'fs__strategy' : {\"space\" : [\"variance\", \"rf_feature_importance\"]},\n","        'fs__threshold': {\"search\" : \"choice\", \"space\" : [0.1, 0.2, 0.3]},\n","\n","        'est__strategy' : {\"space\" : [\"LightGBM\"]},\n","        'est__max_depth' : {\"search\" : \"choice\", \"space\" : [5,6]},\n","        'est__subsample' : {\"search\" : \"uniform\", \"space\" : [0.6,0.9]}\n","\n","        }\n","\n","best = opt.optimise(space, data, max_evals = 5)\n","Predictor().fit_predict(best, data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkzFK_2nH58W"},"source":["#http://epistasislab.github.io/tpot/examples/\n","from tpot import TPOTClassifier\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(iris.data.astype(np.float64),\n","    iris.target.astype(np.float64), train_size=0.75, test_size=0.25, random_state=42)\n","\n","tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n","tpot.fit(X_train, y_train)\n","print(tpot.score(X_test, y_test))\n","tpot.export('tpot_iris_pipeline.py')\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import Normalizer\n","from tpot.export_utils import set_param_recursive\n","\n","# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n","tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n","features = tpot_data.drop('target', axis=1)\n","training_features, testing_features, training_target, testing_target = \\\n","            train_test_split(features, tpot_data['target'], random_state=42)\n","\n","# Average CV score on the training set was: 0.9826086956521738\n","exported_pipeline = make_pipeline(\n","    Normalizer(norm=\"l2\"),\n","    KNeighborsClassifier(n_neighbors=5, p=2, weights=\"distance\")\n",")\n","# Fix random state for all the steps in exported pipeline\n","set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n","\n","exported_pipeline.fit(training_features, training_target)\n","results = exported_pipeline.predict(testing_features)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQbw991TIboA"},"source":["#https://github.com/pycaret/pycaret/blob/master/examples/Fetal%20State%20Classification%20Tutorial%20-FSC101.ipynb\n","from pycaret.classification import *\n","clf=setup(data=df,target='NSP')\n","compare_models()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yr4KmJRCImAo"},"source":["xgboost_classifier=create_model('xgboost')\n","print(xgboost_classifier)\n","tuned_xgboost_classifier=tune_model(xgboost_classifier)\n","plot_model(tuned_xgboost_classifier,plot='class_report')\n","plot_model(tuned_xgboost_classifier,plot='confusion_matrix')\n","save_model(tuned_xgboost_classifier,\"XGBOOST CLASSIFIER\")\n","saved_model=load_model('XGBOOST CLASSIFIER')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGSt0nchJUTC"},"source":["# mljar-supervised package\n","from supervised.automl import AutoML\n","\n","# load the data\n","digits = load_digits()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    pd.DataFrame(digits.data), digits.target, stratify=digits.target, test_size=0.25,\n","    random_state=123\n",")\n","\n","# train models with AutoML\n","automl = AutoML(mode=\"Perform\")\n","automl.fit(X_train, y_train)\n","\n","# compute the accuracy on test data\n","predictions = automl.predict_all(X_test)\n","print(predictions.head())\n","print(\"Test accuracy:\", accuracy_score(y_test, predictions[\"label\"].astype(int)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHhCpOJeGo88"},"source":["#https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#code-examples\n","import h2o\n","from h2o.automl import H2OAutoML\n","\n","# Start the H2O cluster (locally)\n","h2o.init()\n","\n","# Import a sample binary outcome train/test set into H2O\n","train = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv\")\n","test = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv\")\n","\n","# Identify predictors and response\n","x = train.columns\n","y = \"response\"\n","x.remove(y)\n","\n","# For binary classification, response should be a factor\n","train[y] = train[y].asfactor()\n","test[y] = test[y].asfactor()\n","\n","# Run AutoML for 20 base models\n","aml = H2OAutoML(max_models=20, seed=1)\n","aml.train(x=x, y=y, training_frame=train)\n","\n","# View the AutoML Leaderboard\n","lb = aml.leaderboard\n","lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)\n","aml.leader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UxF0iMWbG8yV"},"source":["#https://github.com/ludwig-ai/ludwig\n","from ludwig.api import LudwigModel\n","\n","# train a model\n","config = {...}\n","model = LudwigModel(config)\n","train_stats = model.train(training_data)\n","\n","# or load a model\n","model = LudwigModel.load(model_path)\n","\n","# obtain predictions\n","predictions = model.predict(test_data)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-10-21T12:16:37.100310Z","start_time":"2021-10-21T12:16:23.456954Z"},"id":"4M0beZtBPagP"},"source":["!python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([69, 69])))\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-10-21T12:16:41.346667Z","start_time":"2021-10-21T12:16:41.329664Z"},"id":"IWFhXLrQPagU"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwP7Zt3AQrPo"},"source":["pip install jupyter_http_over_ws\n","jupyter serverextension enable --py jupyter_http_over_ws\n","jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'  --port=8888   --NotebookApp.port_retries=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtALnCf7PagV"},"source":["tf.test.is_gpu_available()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VhqTct5PagW"},"source":["if tf.test.gpu_device_name() == '/device:GPU:0':\n","  print(\"Using a GPU\")\n","else:\n","  print(\"Using a CPU\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElXUEhXUPagX"},"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMnlBGPXPagY"},"source":["with tf.device('/device:CPU:0'):\n","  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n","  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n","  c = tf.matmul(a, b)\n","# Creates a session with log_device_placement set to True.\n","#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n","# Runs the op.\n","#print(sess.run(c))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5yDyivQvCoYR"},"source":["tf.debugging.experimental.enable_dump_debug_info(\"logs\", tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1N11h2kNPagZ"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-10-21T11:43:58.279581Z","start_time":"2021-10-21T11:43:57.383405Z"},"id":"yliethS1Pagb"},"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","le.fit(y)\n","list(le.classes_)\n","values=le.transform(y)\n","print(values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShKBhckkPagb"},"source":["from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder(handle_unknown='ignore')\n","enc.fit(le.transform(y).reshape(-1,1))\n","enc.categories_\n","#print(enc.transform(le.transform(y).reshape(-1,1)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9ukyvUQPagc"},"source":["#print(np.array(tf.one_hot(le.transform(y), depth=3)))\n","#vocabulary_feature_column =  tf.feature_column.categorical_column_with_vocabulary_list(key=[\"P\", \"V\", \"K\"],vocabulary_list=[\"P\", \"V\", \"K\"])\n","import numpy as np\n","n_values = np.max(values) + 1\n","Y=np.eye(n_values)[values]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kLJcxIgPagc"},"source":["#Y=pd.DataFrame(np.array(tf.one_hot(le.transform(y), depth=3)))\n","Y=pd.DataFrame(Y)\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 0)\n","X_train.to_csv(\"X_train.csv\", index = False, header = None)\n","X_test.to_csv(\"X_test.csv\", index = False, header = None)\n","Y_train.to_csv(\"Y_train.csv\", index = False, header = None)\n","Y_test.to_csv(\"Y_test.csv\", index = False, header = None)\n","Y_test.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCfeiN16Pagd"},"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","X_train.shape[1],Y_train.shape[1] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LagqijsbPagd"},"source":["from keras.models import Sequential\n","from keras.layers import Dense"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nOjXMrAPage"},"source":["classifier = Sequential()\n","classifier.add(Dense(units = 9, activation = 'relu', input_dim=X_train.shape[1]))\n","classifier.add(Dense(units = 6, activation = 'relu'))\n","classifier.add(Dense(units = Y_train.shape[1] , activation = 'sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5IoIgykPage"},"source":["classifier.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROoLK5mKPagf"},"source":["classifier.fit(X_train, Y_train, batch_size = X_train.shape[1],epochs = 100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDA4ccHwPagf"},"source":["Y_pred = classifier.predict(X_test)\n","#Y_pred\n","y_pred=(Y_pred.argmax(1)[:,None] == np.arange(Y_pred.shape[1])).astype(int)\n","y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNuFRQrfPagf"},"source":["y_test=Y_test.values\n","y_test=(y_test.argmax(1)[:,None] == np.arange(y_test.shape[1])).astype(int)\n","y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3X9iJ-OPagg"},"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n","cm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0mmresxZPagg"},"source":["# Install TensorFlow Dececision Forests.\n","!pip install tensorflow_decision_forests\n","# Use wurlitzer to capture training logs.\n","!pip install wurlitzer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2P8b4lgPagh"},"source":["import tensorflow_decision_forests as tfdf\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import math\n","import collections\n","try:\n","  from wurlitzer import sys_pipes\n","except:\n","  from colabtools.googlelog import CaptureLog as sys_pipes\n","from IPython.core.magic import register_line_magic\n","from IPython.display import Javascript\n","@register_line_magic\n","def set_cell_height(size):\n","  display(\n","      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n","                 str(size) + \"})\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGJWOsJ0hbGU"},"source":["!ls /content/drive/My*Drive/notebooks/*.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvkBlVv8Pagi"},"source":["#from file icon, right click => https://www.roelpeters.be/running-an-r-kernel-in-google-colab/ \n","#dataset_df = data\n","dataset_df = pd.read_csv(\"/content/drive/MyDrive/Supplementary Table 2 for working purpose.xlsxgene.NARM3CON.csv\")\n","#dataset_df = dataset_df.drop('Unnamed: 0', 1)\n","print(dataset_df.head(3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjaj8Sjtx6AW"},"source":["#dataset_df = pd.read_csv(\"/content/drive/My Drive/Table.csv\")\n","dataset_df = pd.read_csv('/content/drive/MyDrive/notebooks/Supplementary Table 2 for working purpose.xlsxid.csv')\n","print(dataset_df.head(3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Am98JRf1rtfu"},"source":["classes = dataset_df[\"Group\"].unique().tolist()\n","#classes = dataset_df[\"T: Class\"].unique().tolist()\n","print(f\"Label classes: {classes}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikGi4cPCPagj"},"source":["#dataset_tf = tfdf.keras.pd_dataframe_to_tf_dataset(dataset_df, label=\"Mayo Score\")\n","dataset_tf = tfdf.keras.pd_dataframe_to_tf_dataset(dataset_df, label=\"Group\")\n","#dataset_tf = tfdf.keras.pd_dataframe_to_tf_dataset(dataset_df, label=\"T: Class\")\n","model = tfdf.keras.RandomForestModel(compute_oob_variable_importances=True,# growing_strategy=\"BEST_FIRST_GLOBAL\",\n","      num_trees=500,\n","#    max_depth=8,\n","#    split_axis=\"SPARSE_OBLIQUE\",\n","    categorical_algorithm=\"RANDOM\",\n","#hyperparameter_template=\"benchmark_rank1\",\n",")\n","model.compile(metrics=[\"accuracy\"])\n","with sys_pipes():\n","  model.fit(x=dataset_tf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3UZS3vTPagk"},"source":["%set_cell_height 300\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K754gOsxsCeg"},"source":["evaluation = model.evaluate(dataset_tf, return_dict=True)\n","print()\n","for name, value in evaluation.items():\n","  print(f\"{name}: {value:.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-QJ4kfHPagl"},"source":["tfdf.model_plotter.plot_model_in_colab(model, tree_idx=1, max_depth=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT8CwWd1Pagl"},"source":["inspector = model.make_inspector()\n","#?inspector.model_type"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_pdXBbkUTEJ"},"source":["[field for field in dir(inspector) if not field.startswith(\"_\")]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oai_yZ5mbVgd"},"source":["from ipywidgets import interact, interactive, fixed, interact_manual\n","def select_subject(subID):\n","    df_filtered= dataset_df[subID]\n","    ax = df_filtered.apply(np.sum).hist(color=\"orange\")\n","subject = dataset_df.columns\n","interact(select_subject, subID=subject)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmUeyElVUTmg"},"source":["print(\"Model type:\", inspector.model_type())\n","print(\"Number of trees:\", inspector.num_trees())\n","print(\"Objective:\", inspector.objective())\n","print(\"Input features:\", inspector.features())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngq1T-5aUQiH"},"source":["inspector.evaluation()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdNHPeUrUuY4"},"source":["for importance in inspector.variable_importances().keys():\n","  print(\"\\t\", importance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EttXtR-8UzJv"},"source":["inspector.variable_importances()[\"NUM_NODES\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgYI3jgjZzOb"},"source":["inspector.variable_importances()[\"SUM_SCORE\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cknnOlvCaDhL"},"source":["inspector.variable_importances()[\"MEAN_DECREASE_IN_ACCURACY\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn2YMc_tU3XS"},"source":["inspector.extract_tree(tree_idx=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"df2d4uk4VDxq"},"source":["# number_of_use[F] will be the number of node using feature F in its condition.\n","number_of_use = collections.defaultdict(lambda: 0)\n","\n","# Iterate over all the nodes in a Depth First Pre-order traversals.\n","for node_iter in inspector.iterate_on_nodes():\n","\n","  if not isinstance(node_iter.node, tfdf.py_tree.node.NonLeafNode):\n","    # Skip the leaf nodes\n","    continue\n","\n","  # Iterate over all the features used in the condition.\n","  # By default, models are \"oblique\" i.e. each node tests a single feature.\n","  for feature in node_iter.node.condition.features():\n","    number_of_use[feature] += 1\n","\n","print(\"Number of condition nodes per features:\")\n","for feature, count in number_of_use.items():\n","  print(\"\\t\", feature.name, \":\", count,\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0JoprdgsuP1"},"source":["%set_cell_height 150\n","model.make_inspector().training_logs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaSuE12vs74z"},"source":["import matplotlib.pyplot as plt\n","\n","logs = model.make_inspector().training_logs()\n","\n","plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n","plt.xlabel(\"Number of trees\")\n","plt.ylabel(\"Accuracy (out-of-bag)\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n","plt.xlabel(\"Number of trees\")\n","plt.ylabel(\"Logloss (out-of-bag)\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKyhk0Xytjbg"},"source":["print(evaluation)\n","\n","#print(f\"MSE: {evaluation['mse']}\")\n","#print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KM178zASHIDt"},"source":["https://towardsdatascience.com/seeing-numbers-bayesian-optimisation-of-a-lightgbm-model-3642228127b3"]},{"cell_type":"code","metadata":{"id":"dExkCtGRHNps"},"source":["nfold      = 5\n","df=dataset_df\n","df['fold'] = pd.util.hash_pandas_object(df) % nfold\n","print(df['fold'].sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pkb-0Zg_HzDS"},"source":["\n","def cross_val(eta=0.1,num_leaves=8,bag_frac=0.8,bag_freq=5,feat_frac=0.8):\n","    \n","    '''\n","    A function to return cross-validated LightGBM model accuracy\n","    \n","    Inputs\n","      eta: float, learning rate for model\n","      num_leaves: int, maximum number of leaves in tree\n","      bag_frac: float, random bagging fraction\n","      bag_freq: int, frequency of bagging\n","      feat_frac: float, feature fraction\n","    \n","    Outputs\n","      float, model accuracy from best iteration of cross-validated model\n","    '''\n","    \n","    # set the model parameters\n","    parameters = {\n","        'objective': 'multiclass',\n","        'metric': 'multi_error',\n","        'num_class':10,\n","        'learning_rate': eta,\n","        'num_leaves': int(num_leaves), # need to set this as int since optimisation feeds in float\n","        'bagging_fraction': bag_frac,\n","        'bagging_freq': int(bag_freq), # need to set this as int since optimisation feeds in float\n","        'feature_fraction': feat_frac,\n","        'force_col_wise':True, # suppress the warning\n","        'verbosity':-1\n","        }\n","    \n","       \n","    model = lgb.cv(\n","        params = parameters,\n","        train_set = dtrain,\n","        num_boost_round = 500,\n","        early_stopping_rounds = 10,\n","        folds = (([idx for idx in folds.index if folds[idx] != j],\n","                  [idx for idx in folds.index if folds[idx] == j]) for j in range(int(folds.max()))), # custom generator\n","        shuffle = False, # false as we're using our own folds\n","        verbose_eval = -1\n","        )\n","        \n","    \n","    # return accuracy rather than error\n","    # as the optimiser seeks to maximise rather than minimise\n","    return 1. - model['multi_error-mean'][-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Np0tDQ44H9W8"},"source":["space = {\n","    'eta':(0.025,0.15),\n","    'num_leaves':(2,16),\n","    'bag_frac':(0.5,0.8),\n","    'bag_freq':(1,5),\n","    'feat_frac':(0.5,0.8)\n","    }\n","\n","\n","# set up the optimiser\n","optimiser = BayesianOptimization(\n","    f = cross_val,\n","    pbounds = space,\n","    verbose = 2,\n","    random_state = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eKeK1zUImbn"},"source":["cluster = KMeans(n_clusters=10,random_state=0)\n","\n","# empty dict to hold results\n","d = {}\n","\n","# loop through folds\n","for fold in folds.unique():\n","    \n","    # fit cluster on in-fold data\n","    cluster.fit(df_pca[folds!=fold])\n","    \n","    # get out-of-fold predictions\n","    d[fold] = cluster.predict(df_pca)*(1*(folds==fold))\n","\n","# crunch to single column, ready for joining\n","clusters = pd.DataFrame(d).sum(axis=1).to_frame(name='cluster')"],"execution_count":null,"outputs":[]}]}